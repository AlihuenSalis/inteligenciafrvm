{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación (Parte II): Apéndice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumiendo que los errores FP y FN tienen una incidencia distinta en el problema para el cuál utilizamos el clasificador, ¿cómo minimizar el costo de los errores?.\n",
    "\n",
    "* Dadas dos clases 0 y 1, si queremos minimizar el costo de nuestros errores, utilizamos la _loss matrix_\n",
    "\n",
    "$$\n",
    "L =\\begin{pmatrix}{}\n",
    "  & \\hat{y}=0 & \\hat{y}=1 \\\\\n",
    "y=0 & 0 & L_{FP} \\\\\n",
    "y=1 & L_{FN} & 0 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "donde $L_{FN}$ es el costo de un error FN mientras que $L_{FP}$ es el costo de un error FP. La posterior expected loss $L$ para ambas acciones está dada por\n",
    "\n",
    "$$L(\\hat{y}=0 \\mid X)=L_{FN}P(y=1 \\mid X)$$\n",
    "\n",
    "Esta fórmula puede leerse informalmente como \"la pérdida esperada al predecir la clase $0$ dados los datos $X$ equivale a la probabilidad de que nuestro predictor prediga $1$ (esto es porque al ser clasificación binaria, $P(y=1)$ equivale a $1-P(y=0)$, por lo tanto predecir $1$ equivale a \"no predecir $0$\") por el costo de tal predicción (en este caso $L_{FN}$)\". Análogamente,\n",
    "\n",
    "$$L(\\hat{y}=1 \\mid X)=L_{FP}P(y=0 \\mid X)$$\n",
    "\n",
    "Al buscar eliminar la loss, deberíamos escoger la clase 1 siempre que\n",
    "\n",
    "$L(\\hat{y}=0 \\mid X) > L(\\hat{y}=1 \\mid X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazando, queda como equivalente a\n",
    "\n",
    "$L_{FN}P(y=1 \\mid X) > L_{FP}P(y=0 \\mid X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la diferencia entre ambos errores es constante, es decir que $L_{FN} = c L_{FP}$, dividiendo ambos términos por $L_{FN}$, elegiremos $\\hat{y}=1$ si\n",
    "\n",
    "$$P(y=1 \\mid X) > \\frac{1}{c} P(y=0 \\mid X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa esto? Significa que si un FN cuesta 2 veces lo que un FP (lo que implica un $c=2$), elegiremos $\\hat{y}=1$ siempre que $P(y=1 \\mid X) > \\frac{1}{2} P(y=0 \\mid X)$; es decir que lo elegiremos siempre que $P(y=1 \\mid X) > 0.33$. Se demuestra a continuación por qué en este caso el umbral sería de $0.33$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollando, y teniendo en cuenta que estamos ante un problema de clasificación binaria, si $P(y=1 \\mid X) = p$ entonces $P(y=0 \\mid X) = (1-p)$, por lo tanto\n",
    "\n",
    "$$\\begin{eqnarray}{\n",
    "p > \\frac{1}{c} (1-p) \\\\\n",
    "p > \\frac{1}{c} - \\frac{p}{c} \\\\\n",
    "p + \\frac{p}{c} > \\frac{1}{c} \\\\\n",
    "\\frac{cp + p}{c} > \\frac{1}{c} \\\\\n",
    "\\frac{(c+1)p}{c} > \\frac{1}{c} \\\\\n",
    "}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "despejando $p$...\n",
    "\n",
    "$$p > \\frac{1}{c+1}$$\n",
    "\n",
    "Por lo tanto, si $c=2$, entonces equivale a establecer un umbral de clasificación como positivo de $0.33$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
