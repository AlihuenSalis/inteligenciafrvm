{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción al Aprendizaje Supervisado - Clasificación (Parte II)\n",
    "\n",
    "* Pre-procesamiento de los datos.\n",
    "* Evaluación de un clasificador.\n",
    "* FPR vs FNR tradeoff.\n",
    "\n",
    "5to año - Ingeniería en Sistemas de Información\n",
    "\n",
    "Facultad Regional Villa María"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-procesamiento de datos\n",
    "\n",
    "Un problema muy frecuente (en industria es uno de los problemas más reportados en ML) es que los datasets \"crudos\" no pueden recibir entrenamiento tal como están, por lo que necesitan un pre-procesamiento para poder adaptarse a los requerimientos del modelo. Vemos algunos métodos de pre-procesamiento comunes:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de features que no aportan a la predicción\n",
    "\n",
    "Un problema común en los datasets es que muchas veces los mismos tienen algunas variables que no están relacionadas de ninguna forma con las salidas o bien es sabido a priori que no aportan información significativa para predecir la salida.\n",
    "\n",
    "* Un ejemplo común son los identificadores, los cuales asocian cada fila de datos con un único código de identificación.\n",
    "\n",
    "* Estos features deben eliminarse, porque de lo contrario el modelo los ajustará e intentará hacer predicciones con datos que no tienen aporte alguno, empeorando la calidad general del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ampliación o transformación del dataset\n",
    "\n",
    "De forma similar, existen maneras de agregar o transformar datos en el dataset para mejorar las predicciones, por ejemplo incorporando información de datasets públicos o generando nuevos features a partir de los existentes o con la ayuda de información de dominio.\n",
    "\n",
    "* Este tipo de mejoras puede ayudar a mejorar las predicciones del dataset, por ejemplo al poder utilizar features más relevantes para predecir las salidas.\n",
    "\n",
    "* Al igual que al eliminar los features (más allá de aquellos obvios como los identificadores), no hay una regla general para ampliar el dataset, pues depende mucho del dominio del problema. Vamos a ver un ejemplo práctico de esto en la clase donde se presenta la Minería de Texto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variables para datasets con features no numéricos\n",
    "\n",
    "* Por ejemplo, si tenemos que hacer una predicción y tenemos una variable categórica como por ejemplo \"Género\" que toma valores \"Mujer\" y \"Varón\", tal variable no puede ser utilizada de esa forma para hacer la predicción, puesto que los modelos emplean features numéricos.\n",
    "* Una solución rápida consistiría en reemplazar los features asignando, por ejemplo, 0 cuando se trata de \"Mujer\" y 1 cuando se trata de \"Varón\", es decir\n",
    "\n",
    "|        | Género |\n",
    "|--------|:------:|\n",
    "| Ana    |    0   |\n",
    "| José   |    1   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El problema de este enfoque es que asumimos arbitrariamente un orden en los features, por lo cual nuestro modelo estaría innecesariamente sesgado en su entrenamiento.\n",
    "* El enfoque utilizado para estos casos consiste en crear un nuevo feature para cada valor categórico posible, asignando un 1 cuando el valor pertenece a la mencionada categoría y un 0 para todas las demás categorías.\n",
    "* Las variables de esta forma reciben el nombre de \"dummy variable\".\n",
    "\n",
    "|        | Mujer | Varón |\n",
    "|--------|:-----:|:-----:|\n",
    "| Ana    |   1   |   0   |\n",
    "| José   |   0   |   1   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalización de los datos\n",
    "\n",
    "En virtud de que todos los features **contribuyan de forma equitativa** (es decir que no tengan más peso en la clasificación aquellos features con mayor magnitud), para algunos modelos se requiere que los datos estén normalizados de alguna forma, por ejemplo para que todos los valores caigan en el mismo rango fijo. La normalización se hace en cada feature. Informalmente, \"para cada columna\".\n",
    "\n",
    "\n",
    "* Una normalización posible es **minmax normalization**, la cual transforma un feature de tal forma que todos sus valores caigan en el rango $[0,1]$.\n",
    "* Para lograr esto es suficiente hacer, para cada elemento $j$ del feature $X_i$\n",
    "\n",
    "$$Z_{ij} = \\frac{X_{ij} - min(X_{i})}{max(X_{i}) - min(X_{i})}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo: dados los siguientes datos,\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "| 42        |\n",
    "| 66        |\n",
    "| 187       |\n",
    "| 29        |\n",
    "\n",
    "Normalizando...\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "| 0.08      |\n",
    "| 0.23      |\n",
    "| 1         |\n",
    "| 0         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Otra normalización muy común es la **z-score standarization**, normaliza los valores con respecto a la desviación estándar, dejando los mismos con media 0. Analíticamente, $$Z_{ij} = \\frac{X_{ij} - \\bar{X}}{\\sigma}$$ donde $\\bar{X}$ es la media de la población y $\\sigma$ es la desviación estándar.\n",
    "\n",
    "* Cada valor $Z_{ij}$ normalizado representa la distancia entre el valor $X_{ij}$ y la media de la población, en $Z_{ij}$ desviaciones estándar como unidad.\n",
    "\n",
    "Normalizando los datos iniciales del ejemplo el ejemplo anterior...\n",
    "\n",
    "| Feature_1 |\n",
    "|:---------:|\n",
    "|-0.62      |\n",
    "|-0.23      |\n",
    "| 1.69      |\n",
    "|-0.83      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué sucede cuando queremos normalizar y tenemos que dividir los datos en train y test (o, análogamente, en train y validation)?\n",
    "\n",
    "Si normalizamos toda nuestra matriz de datos X, tendremos un problema: estaremos sesgando indirectamente nuestro entrenamiento con respecto a los conjuntos de test y de validación.\n",
    "\n",
    "Lo que se hace en estos casos es:\n",
    "\n",
    "* Obtener $\\bar{X}_{train}$ y $\\sigma_{train}$ para el caso de normalización z-score, o $min(X_i)_{train}$ y $max(X_i)_{train}$ para el caso de minmax.\n",
    "* Aplicar la normalización al conjunto de entrenamiento.\n",
    "* Al hacer predicciones, normalizar el conjunto de validación o test **con respecto a los estadísticos del conjunto de entrenamiento**, es decir $\\bar{X}_{train}$ y $\\sigma_{train}$ (para el caso de z-score). Es decir, que para normalizar el conjunto de test, hacemos para cada uno de sus $X_{ij}$:\n",
    "\n",
    "$$Z_{ij} = \\frac{X_{ij} - \\bar{X}_{train}}{\\sigma_{train}}$$\n",
    "\n",
    "Naturalmente, si hacemos esto perderemos alguna de las propiedades de la normalización para el conjunto de test (por ejemplo, en el caso de z-score, es muy probable que la media y desviación de los datos de test difieran de 0 y 1, respectivamente), pero esto es totalmente preferible antes que sesgar el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluando un clasificador\n",
    "\n",
    "La forma más simple de evaluar un clasificador es mediante el porcentaje de aciertos, es decir qué porcentaje de nuestras predicciones predijeron correctamente la clase de todos los puntos consultados.\n",
    "\n",
    "* Retomamos el ejemplo de la clase pasada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 2 0 1 2 1 0 1 1 1 1 0 0 1 2 0 0 0 2 2 1 0 2 0 1 1 1 2 2 1 2 1 2 0 2\n",
      " 1 2 1 0 0 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "# Dividimos el conjunto en train, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=10, test_size=0.3)\n",
    "\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_hat = clf.predict(X_test)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de aciertos en la clasificación:  0.711111111111\n"
     ]
    }
   ],
   "source": [
    "print('Porcentaje de aciertos en la clasificación: ', clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esta métrica es una buena medida para saber rápidamente la tasa de aciertos en todo clasificador. Sin embargo no nos está dando detalles como, por ejemplo, que todas las Setosas fueron correctamente clasificadas. Para ello vamos a usar mejor información, que incluya las métricas comúnmente utilizadas para evaluar un clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de errores\n",
    "\n",
    "En la clasificación binaria (es decir cuando la cantidad de clases posibles a la que una variable puede pertenecer es de dos), al intentar hacer una predicción, existen dos tipos de errores de predicción a considerar.\n",
    "\n",
    "Por ejemplo, supongamos que testeamos la existencia de una enfermedad en un paciente. Como _hipótesis nula_ $h_0$ tomamos a \"$h_0$: el paciente no posee la enfermedad\", mientras que como _hipótesis alternativa_ tomamos \"$h_1$: el paciente posee la enfermedad\".\n",
    "\n",
    "* $h_0$ es la hipótesis que se suele usar para establecer \"ausencia o inexistencia de relación entre dos fenómenos\" (tomando como fenómenos el paciente y la enfermedad), mientras que $h_1$ representa \"algún tipo de relación entre dos fenómenos\".\n",
    "\n",
    "* \"_Inocente hasta que se demuestre lo contrario_\". En testing de hipótesis, $h_0$ es la postura por defecto. Esto quiere decir que para rechazarla y por lo tanto validar una hipótesis alternativa debe demostrarse fehacientemente que $h_0$ es falsa más allá de toda duda razonable (normalmente representada por un intérvalo de confianza de 1% o 5%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El **error de tipo I** o **false positive** ocurre cuando se rechaza incorrectamente una $h_0$ verdadera. En nuestro ejemplo, esto sucede cuando incorrectamente diagnosticamos la enfermedad en el paciente.\n",
    "\n",
    "* Por otra parte, el **error de tipo II** o **false negative**, ocurre cuando incorrectamente se retiene una $h_0$ falsa, siendo que se daba $h_1$. En nuestro ejemplo esto sucede cuando detectamos incorrectamente que el paciente no registra la enfermedad.\n",
    "\n",
    "* En el caso de que la predicción haya sido correcta, decimos que la misma arrojó un **true positive** o **true negative** (_positive_ significa que existe relación entre dos fenómenos).\n",
    "\n",
    "* En nuestro caso, true positive representa la correcta predicción en la existencia de la enfermedad mientras que false positive representa correctamente la predicción sobre la ausencia de la enfermedad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En nuestro ejemplo, si detectáramos varias enfermedades en el paciente y nos interesa saber $h_0$, true negative se referirá a los casos donde predecimos que el paciente no posee ninguna enfermedad y tal situación es la real; mientras que true positive se refiere a haber inferido correctamente que el paciente posee alguna enfermedad. Este enfoque se conoce como **one-vs-all**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "\n",
    "Una forma sencilla de evaluar el rendimiento de un algoritmo es por medio de una **confusion matrix** o **error matrix**, la cual contrasta las predicciones con los valores verdaderos, mostrando los errores TI y TII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  0  0]\n",
      " [ 0 10  7]\n",
      " [ 0  6  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_hat, labels=[0,1,2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateando:\n",
    "\n",
    "|                   |            |        |Clase estimada |           |\n",
    "|-------------------|------------|:------:|:-------------:|:---------:|\n",
    "|                   |            | Setosa |   Versicolor  | Virginica |\n",
    "|                   | Setosa     | **14** |        0      |     0     |\n",
    "|**Clase verdadera**| Versicolor |    0   |      **10**   |     7     |\n",
    "|                   | Virginica  |    0   |        6      |   **8**   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En el caso de la **clasificación muticlase**, para algunos algoritmos se usa la estrategia \"one-vs-all\" para referirse a los tipos de errores. Es decir que cada tipo de error es calculado para cada una de las clases, tomando un label de dicha clase como positivo ($y=1$) y un label de cualquier otra clase como negativo ($y=0$). \n",
    "\n",
    "* Ejemplo: clasificación multiclase desde las setosas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                   |                    |     Clase estimada      |                            |\n",
    "|-------------------|--------------------|:-----------------------:|:--------------------------:|\n",
    "|                   |                    | No Setosa ($\\hat{y}=0$) |    Setosa ($\\hat{y}=1$)    |\n",
    "|                   | No Setosa ($y=0$)  |       **31**            |             0              |\n",
    "|**Clase verdadera**| Setosa    ($y=1$)  |          0              |          **14**            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Esto se hace para poder extender el problema a partir de una clasificación binaria, pudiendo evaluar los errores TI y TII de la misma forma.\n",
    "\n",
    "* Vemos ahora con mejor nivel de detalle aspectos como que las 14 flores Setosa utilizadas para el test fueron correctamente clasificadas, mientras que las flores Versicolor se confunden frecuentemente con las Virginica.\n",
    "\n",
    "Vamos a procesar todavía más esta información al calcular métricas adicionales que nos permitirán obtener más claridad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Positives - Negatives](images/positives_negatives.png)\n",
    "\n",
    "Fuente: Walber (usuario de Wikipedia), imagen adaptada desde https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concepto preliminar: en la clasificación binaria, es decir aquellos problemas donde $c_i \\in \\{False, True\\}$, el **umbral** o _threshold_ $\\theta \\in [0,1]$ es la probabilidad mínima que hace que el predictor clasifique una observación como True. Aquellas probabilidades por debajo del umbral son clasificadas como False.\n",
    "\n",
    "Por ejemplo, un $\\theta = 0.75$ hace necesario que $P(y=1 \\mid x) > 0.75$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas desde el punto de vista de los negativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La primera métrica es el **false positive rate (FPR)** (o proporción de falsas alarmas), que representa el porcentaje de errores de TI en la clasificación, es decir\n",
    "\n",
    "$$ FPR = \\frac{FP}{\\text{actual negatives}} = \\frac{FP}{FP + TN}$$\n",
    "\n",
    "Un predictor no tendría falsas alarmas si se clasificara todo como \"False\", al usar un umbral $\\theta=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, el **false negative rate (FNR)** (o proporción de detecciones perdidas) representa el porcentaje de errores TII en la clasificación, es decir\n",
    "\n",
    "$$ FNR = \\frac{FN}{\\text{actual positives}} = \\frac{FN}{FN + TP}$$\n",
    "\n",
    "Un predictor no tendría detecciones perdidas si clasificara todo como \"True\", usando un umbral $\\theta = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas desde el punto de vista de los positivos\n",
    "\n",
    "![](images/precision_recall.png)\n",
    "\n",
    "Fuente: Walber (usuario de Wikipedia), imagen adaptada desde https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los indicadores principales es el **positive predictive value** o **precision**, que representa el porcentaje de positivos correctamente inferidos como tal por cada positivo inferido. Está dado por\n",
    "\n",
    "$$P(y=1 \\mid \\hat{y}=1) = \\frac{TP}{\\text{predicted positives}} = \\frac{TP}{TP + FP}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como \"qué tan seguro es un clasificador al inferir las observaciones como positivas\". Un predictor maximizaría esta métrica si clasificara como \"True\" sólo aquellas observaciones con las que cuente con total certeza que son \"True\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro indicador principal es el **true positive rate**, **sensitivity** o **recall**, que representa el porcentaje de positivos correctamente inferidos por cada positivo real, dado por\n",
    "\n",
    "$$P(\\hat{y}=1 \\mid y=1)= \\frac{TP}{\\text{actual positives}} = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como \"qué tan bueno es un clasificador en detectar los positivos\". Un predictor sería perfecto en la detección de positivos si clasificara todo como \"True\", al usar un umbral $\\theta = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análogamente, el **true negative rate** o **specificity** es similar al recall pero considerando los negativos, es decir\n",
    "\n",
    "$$P(\\hat{y}=0 \\mid y=0)= \\frac{TN}{\\text{actual negatives}} = \\frac{TN}{TN + FP}$$\n",
    "\n",
    "Intuitivamente puede interpretarse como \"qué tan bueno es un clasificador evitando las falsas alarmas\". Como vimos antes, un predictor sería perfecto en evitar falsas alarmas si clasificara todo como \"False\", es decir usara un $\\theta=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera medida que vimos, el porcentaje de aciertos (**accuracy**) está dada por\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\text{correctly predicted}}{\\text{all predicted}} = \\frac{TP + TN}{TP + FP + TN + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es trivial y poco útil maximizar una métrica por separado, un buen clasificador debería, en general (y dependiendo del problema que trata de resolver), intentar maximizar conjuntamente tanto precision como recall. Normalmente ambos representan intereses contrapuestos.\n",
    "\n",
    "* Considerar como ejemplo la extracción de un tumor cerebral, donde un cirujano debe intentar maximizar la cantidad de células cancerígenas extraídas (recall) para evitar que se regenere el tumor, minimizando a su vez la cantidad de células no cancerígenas extraídas (precision) que podrían afectar las funciones cerebrales.\n",
    "\n",
    "* Debido a que ambas métricas van de la mano, para evaluarlas conjuntamente se suele usar el F1 score, dado por la media armónica\n",
    "\n",
    "$$F_1 = \\frac{2}{P^{-1}+R^{-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn convenientemente hace este procesamiento por nosotros, como vemos a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00        14\n",
      " versicolor       0.62      0.59      0.61        17\n",
      "  virginica       0.53      0.57      0.55        14\n",
      "\n",
      "avg / total       0.71      0.71      0.71        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_hat, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que _support_ es la cantidad de instancias (true values) de cada una de las clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive vs false negative tradeoff\n",
    "\n",
    "Como acabamos de ver, la contraposición de intereses en un clasificador se da porque existe una relación inversa entre los errores false positive (falsa alarma) y los errores false negative (detección perdida).\n",
    "\n",
    "* La inclinación que querramos darle a este tradeoff depende del problema que estemos intentando resolver.\n",
    "\n",
    "* Para aquellas tareas que se desempeñan en entornos con aversión al riesgo, como vemos en el ejemplo de la cirugía cerebral, debemos diseñar nuestro clasificador de tal forma que se minimicen los costos totales producidos por los errores de predicción.\n",
    "\n",
    "* En la clasificación binaria, una de las opciones es incluir una **reject region**, es decir un umbral de probabilidad donde el predictor, en lugar de clasificar como False, no tomará decisiones, dejando las mismas en manos de una persona, por ejemplo.\n",
    "\n",
    "![](images/reject_region.png)\n",
    "\n",
    "Fuente: Figura 1.26 de Bishop 2006a (nota: no confundir $\\theta$ utilizado en la figura y en el notebook para denotar un umbral con $\\theta$ comúnmente utilizado para referirse a los híper-parámetros del predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativamente, si queremos tomar esa decisión pero que nuestro clasificador sea conservador debido al posible costo de los errores, podemos usar el mismo umbral para definir hasta cuánto debe ser nuestro grado de seguridad para asegurar o rechazar $h_0$.\n",
    "\n",
    "* En los clasificadores probabilísticos vistos aquí, el umbral es establecido al ver la probabilidad de predicción de as distintas clases, y alterando la clase elegida cuando la misma no supera el umbral.\n",
    "\n",
    "* Por defecto, el umbral utilizado en los clasificadores binarios es $\\theta=0.5$, mientras que en los clasificadores multi-clase se selecciona la clase que arroje mayor probabilidad.\n",
    "\n",
    "* Veamos las probabilidades de nuestro predictor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.49055281  0.50944719]\n",
      " [ 0.          0.27075062  0.72924938]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.82398271  0.17601729]\n",
      " [ 0.          0.43565179  0.56434821]\n",
      " [ 0.          0.5         0.5       ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          1.          0.        ]\n",
      " [ 0.          1.          0.        ]\n",
      " [ 0.          0.5         0.5       ]\n",
      " [ 0.          0.92108116  0.07891884]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.57698118  0.42301882]\n",
      " [ 0.06713528  0.22517858  0.70768614]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.3238972   0.6761028 ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.51724172  0.48275828]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.76678183  0.23321817]\n",
      " [ 0.          0.83724452  0.16275548]\n",
      " [ 0.          0.59872806  0.40127194]\n",
      " [ 0.          0.06941235  0.93058765]\n",
      " [ 0.          0.43908148  0.56091852]\n",
      " [ 0.          0.50785178  0.49214822]\n",
      " [ 0.          0.19582665  0.80417335]\n",
      " [ 0.          0.76908729  0.23091271]\n",
      " [ 0.          0.43565179  0.56434821]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.          1.        ]\n",
      " [ 0.          0.5         0.5       ]\n",
      " [ 0.          0.10628176  0.89371824]\n",
      " [ 0.          0.5         0.5       ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.10062565  0.71075411  0.18862023]\n",
      " [ 0.49422963  0.36856342  0.13720695]\n",
      " [ 0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict_proba(X_test))\n",
    "\n",
    "# cada una de las columnas de salida representa la probabilidad estimada por el clasificador para cada una de las clases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, en determinadas situaciones es deseable cambiar el umbral, por ejemplo...\n",
    "\n",
    "1. Los errores FP y FN tienen una incidencia distinta en el problema para el cuál utilizamos el clasificador.\n",
    "2. Deseamos testear la certeza con la que nuestro clasificador toma las decisiones.\n",
    "\n",
    "Analizamos ambos casos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">1. Los errores FP y FN tienen una incidencia distinta en el problema para el cuál utilizamos el clasificador.\n",
    "\n",
    "* Dadas dos clases 0 y 1, si queremos minimizar el costo de nuestros errores, utilizamos la _loss matrix_\n",
    "\n",
    "$$\n",
    "L =\\begin{pmatrix}{}\n",
    "  & \\hat{y}=0 & \\hat{y}=1 \\\\\n",
    "y=0 & 0 & L_{FP} \\\\\n",
    "y=1 & L_{FN} & 0 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "donde $L_{FN}$ es el costo de un error FN mientras que $L_{FP}$ es el costo de un error FP. La posterior expected loss $L$ para ambas acciones está dada por\n",
    "\n",
    "$$L(\\hat{y}=0 \\mid X)=L_{FN}P(y=1 \\mid X)$$\n",
    "\n",
    "Esta fórmula puede leerse informalmente como \"la pérdida esperada al predecir la clase $0$ dados los datos $X$ equivale a la probabilidad de que nuestro predictor prediga $1$ (esto es porque al ser clasificación binaria, $P(y=1)$ equivale a $1-P(y=0)$, por lo tanto predecir $1$ equivale a \"no predecir $0$\") por el costo de tal predicción (en este caso $L_{FN}$)\". Análogamente,\n",
    "\n",
    "$$L(\\hat{y}=1 \\mid X)=L_{FP}P(y=0 \\mid X)$$\n",
    "\n",
    "Al buscar eliminar la loss, deberíamos escoger la clase 1 siempre que\n",
    "\n",
    "$L(\\hat{y}=0 \\mid X) > L(\\hat{y}=1 \\mid X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazando, queda como equivalente a\n",
    "\n",
    "$L_{FN}P(y=1 \\mid X) > L_{FP}P(y=0 \\mid X)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si la diferencia entre ambos errores es constante, es decir que $L_{FN} = c L_{FP}$, dividiendo ambos términos por $L_{FN}$, elegiremos $\\hat{y}=1$ si\n",
    "\n",
    "$$P(y=1 \\mid X) > \\frac{1}{c} P(y=0 \\mid X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué significa esto? Significa que si un FN cuesta 2 veces lo que un FP (lo que implica un $c=2$), elegiremos $\\hat{y}=1$ siempre que $P(y=1 \\mid X) > \\frac{1}{2} P(y=0 \\mid X)$; es decir que lo elegiremos siempre que $P(y=1 \\mid X) > 0.33$. Se demuestra a continuación por qué en este caso el umbral sería de $0.33$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desarrollando, y teniendo en cuenta que estamos ante un problema de clasificación binaria, si $P(y=1 \\mid X) = p$ entonces $P(y=0 \\mid X) = (1-p)$, por lo tanto\n",
    "\n",
    "$$\\begin{eqnarray}{\n",
    "p > \\frac{1}{c} (1-p) \\\\\n",
    "p > \\frac{1}{c} - \\frac{p}{c} \\\\\n",
    "p + \\frac{p}{c} > \\frac{1}{c} \\\\\n",
    "\\frac{cp + p}{c} > \\frac{1}{c} \\\\\n",
    "\\frac{(c+1)p}{c} > \\frac{1}{c} \\\\\n",
    "}\n",
    "\\end{eqnarray}$$\n",
    "\n",
    "despejando $p$...\n",
    "\n",
    "$$p > \\frac{1}{c+1}$$\n",
    "\n",
    "Por lo tanto, si $c=2$, entonces equivale a establecer un umbral de clasificación como positivo de $0.33$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2\\. Deseamos testear la certeza con la que nuestro clasificador toma las decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Receiver operating characteristic (ROC) curve\n",
    "\n",
    "* Los umbrales también pueden utilizarse para evaluar la _certeza_ de nuestro clasificador, es decir con qué margen de confianza infiere la clase de cada una de las observaciones, para de esta manera poder compararlo mejor frente a otros clasificadores en cuanto a su capacidad de generalizar.\n",
    "\n",
    "* Por ejemplo, el clasificador A y el clasificador B pueden tener idénticas predicciones para un dataset, pero A estar clasificando a todas las clases con un 95% de probabilidad y B estar clasificando con un 51%.\n",
    "\n",
    "* Distinguir entre ambos clasificadores es precisamente la idea de las curvas ROC. En ellas se muestra cómo se comparan los distintos clasificadores en términos de TPR y FPR con respecto a la suposición aleatoria (elige clase 0 o 1 aleatoriamente) y al clasificador perfecto, mostrando el equilibrio entre true positives y false positives para las distintas instancias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Veamos cómo se ve una curva ROC para nuestro ejemplo. Fuente: https://github.com/reiinakano/scikit-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# instalamos la dependencia requerida\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "try: # try usado porque la invocación de pip cambia según la versión del mismo\n",
    "    from pip import main as pipmain # pip 9\n",
    "except:\n",
    "    from pip._internal import main as pipmain # pip 10\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pipmain([\"install\", \"scikit-plot\"])\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe05393b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scikitplot as skplt\n",
    "\n",
    "y_hat_probas = clf.predict_proba(X_test)\n",
    "\n",
    "# predicted probabilities generated by sklearn classifier\n",
    "skplt.metrics.plot_roc(y_test, y_hat_probas, plot_micro=False, plot_macro=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notar que micro-average ROC curve es el promedio de las áreas de las curvas ROC, mientras que macro-average ROC curve es el mismo promedio pero ponderado por la cantidad de observaciones de cada clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para comparar la calidad de las curvas ROC, una medida utilizada es comparar su área bajo la curva de cada clasificador.\n",
    "\n",
    "* Notar que cualquier clasificador puede alcanzar el límite inferior izquierdo (TPR=FPR=0) al setear $\\theta=1$ y por lo tanto clasificar todo como 0. Análogamente, setear $\\theta=0$ hará que todos los resultados sean clasificados como 1, obteniendo (TPR=FPR=1).\n",
    "\n",
    "* Trazar una línea (TPR=FPR) muestra cómo se desempeña el clasificador aleatorio, el cual es el piso mínimo que todo clasificador debe superar.\n",
    "\n",
    "* Para medir la perfomance de los clasificadores de acuerdo a sus curvas ROC, el criterio utilizado es el de calcular el área bajo la curva ROC (número real que va de 0 a 1). Esta, junto con precision, recall, f1 y la tasa de aciertos, es otra métrica muy útil para evaluar el rendimiento de nuestro clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver solamente la métrica del AUC de la curva ROC se puede usar esta librería (sólo para clasificación binaria):\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajo Práctico 3 - Parte II\n",
    "\n",
    "Para los siguientes ejercicios vamos a usar el Wisconsin Breast Cancer dataset, construido a partir de imágenes digitalizadas. Las mismas describen la información obtenida de cada imagen de célula mamaria biopsiada, especificando si el diagnóstico sobre la misma es que es benigna o maligna. Fuente: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic).\n",
    "\n",
    "\n",
    "#### Ejercicios Básicos\n",
    "\n",
    "1. Aplicarle normalización z-score a los datos. Dividir en conjunto de train, validación y test. Nota: para implementar esto se puede utilizar kFolds o bien hacer una sola vez la división.\n",
    "\n",
    "2. Implementar un clasificador kNN para todos los features el dataset Wisconsin Breast Cancer (plantilla de código provista debajo). Entrenarlo y determinar su híper-parámetro k de acuerdo a la tasa de aciertos, usando el subconjunto de validación. Tras finalizar el entrenamiento, mostrar en pantalla la correspondiente tasa de aciertos, precision, recall, f1-score, área bajo la curva ROC y matriz de confusión.\n",
    "\n",
    "\n",
    "Aclaración: el inciso 1 de los ejercicios básicos no considera la aclaración realizada en clase y modificación posterior del notebook, en las cuales se explica cómo normalizar con el train-test split. Por lo tanto, considerando que la aclaración se realizó luego de presentar los ejercicios, se permite realizar la normalización tanto del conjunto $X$ en su totalidad como del conjunto $X_{train}$, tal como fue comentado en clase.\n",
    "\n",
    "#### Ejercicios Complementarios\n",
    "\n",
    "1. Considerar el caso donde un incorrecto diagnóstico de cáncer cuando la célula es benigna tiene un costo de 7, mientras que una errónea omisión de una célula maligna tiene un costo de 18. De acuerdo a lo visto en este notebook, modificar las salidas del clasificador para que el mismo realice la mayor reducción posible del costo por errores de clasificación, y mostrar la matriz de confusión para la salida modificada.\n",
    "\n",
    "2. Considerando el punto anterior, modificar el código del ejercicio básico para que que cambie el criterio de optimización del híper-parámetro k, de modo que el mismo apunte a minimizar el costo de los errores de predicción, en lugar de maximizar la tasa de aciertos. Mostar en pantalla cuál es el costo mínimo obtenido tras dicha minimización, junto a su correspondiente k.\n",
    "\n",
    "\n",
    "#### Ejercicios Extra\n",
    "\n",
    "La segunda parte de este trabajo práctico no tiene ejercicios extra. Por lo tanto, los puntos por ejercicios extra obtenidos en la parte anterior se aplicarán también a la segunda parte y, en consecuencia, se admite la entrega para su corrección de los ejercicios extra de la primera parte en la entrega de la segunda parte del trabajo.\n",
    "\n",
    "Fecha de entrega: **16/5/2018 23:55**.\n",
    "\n",
    "Nota: la resolución de los ejercicios es **individual**. La reutilización del código del notebook está permitida (por ejemplo para confeccionar gráficos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "# Código inicial\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# En el siguiente ejercicio, al no emplear gráficos, vamos a apuntar a obtener el mejor\n",
    "# rendimiento posible de nuestro estimador, por lo que vamos a tomar la dimensionalidad completa del dataset,\n",
    "# lo que significa que no vamos a elegir un feature en concreto como en la clase pasada sino todos los features\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Nota: tener en cuenta que, en este dataset, y==0 representa que la célula es maligna mientras que\n",
    "# un y==1 representa que la célula es benigna. Se aclara esto dado que puede generar confusión\n",
    "# debido a que difiere del criterio en el cual el 0 representa la ausencia de relación de dos\n",
    "# fenómenos\n",
    "print(data.target_names)\n",
    "\n",
    "# TODO seguir aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Información sobre el dataset\n",
    "# help(load_breast_cancer)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
